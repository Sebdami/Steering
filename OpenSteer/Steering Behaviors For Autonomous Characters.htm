<html><head><!--This file created by ClarisWorks HTML Filter 2.0--><!-- Autogenerated version made on March 10, 1999 --><!-- subsequent modifications made by hand --><title>Steering Behaviors For Autonomous Characters</title>






<meta name="GENERATOR" content="ClarisWorks HTML Filter 2.0">

<meta name="description" content="This paper presents solutions for one requirement of autonomous
	characters in animation and games: the ability to navigate around
	their world in a life-like and improvisational manner.">
<meta name="keywords" content="Animation Techniques, Virtual/Interactive Environments, Games,
	Simulation, behavioral animation, autonomous agent, situated,
	embodied, reactive, vehicle, steering, path planning, path
	following, pursuit, evasion, obstacle avoidance, collision
	avoidance, flocking, group behavior, navigation, artificial life,
	improvisation"></head><body bgcolor="#ffffff">

<div align="center">
<font size="5">
<br>
<b>
Steering Behaviors For Autonomous Characters
</b>
<br>
</font>
<br>
<font size="4">Craig W. Reynolds</font>
<br>
<br>
Sony Computer Entertainment America
<br>
<font size="2">919 East Hillsdale Boulevard
<br>
Foster City, California 94404
<br>
<br>
<a href="mailto:craig_reynolds@playstation.sony.com">
craig_reynolds@playstation.sony.com</a>
<br>
<a href="http://www.red.com/cwr/">http://www.red.com/cwr/</a>
<br>
<a href="mailto:cwr@red.com">cwr@red.com</a>
<br>
</font>
</div>

<blockquote>
<p>
<br>
<font size="2">
<b>Keywords</b>: animation techniques, virtual/interactive environments,
games, simulation, behavioral animation, autonomous agent, situated,
embodied, reactive, vehicle, steering, path planning, path following,
pursuit, evasion, obstacle avoidance, collision avoidance, flocking, group
behavior, navigation, artificial life, improvisation.<br>
</font></p></blockquote>

<p></p>

<h3>Abstract</h3>

<p>
This paper presents solutions for one requirement of autonomous characters
in animation and games: the ability to navigate around their world in a
life-like and improvisational manner.  These &#8220;steering behaviors&#8221;
are largely independent of the particulars of the character&#8217;s means of
locomotion.  Combinations of steering behaviors can be used to achieve
higher level goals (For example: get from here to there while avoiding
obstacles, follow this corridor, join that group of characters...)  This
paper divides motion behavior into three levels.  It will focus on the
middle level of steering behaviors, briefly describe the lower level of
locomotion, and touch lightly on the higher level of goal setting and
strategy.
</p>

<h3>Introduction</h3>

<p>
<i>Autonomous characters</i> are a type of <i>autonomous agent</i> intended
for use in computer animation and interactive media such as games and
virtual reality.  These agents represent a character in a story or game and
have some ability to improvise their actions.  This stands in contrast both
to a character in an animated film, whose actions are scripted in advance,
and to an &#8220;avatar&#8221; in a game or virtual reality, whose actions
are directed in real time by a human player or participant.  In games,
autonomous characters are sometimes called <i>non-player characters</i>.
</p>
<p>
An autonomous character must combine aspects of an autonomous robot with
some skills of a human actor in improvisational theater.  These characters
are usually not real robots, and are certainly not human actors, but share
some properties of each.
</p>
<p>
The term &#8220;autonomous agent&#8221; is used in many contexts, so the
following is an attempt to locate the terminology of this paper in relation
to other fields of study.  An autonomous agent can exist in isolation, or
it can be <i>situated</i> in a world shared by other entities.  A
&#8220;data mining&#8221; agent is an example of the former, and a controller
for a power grid is an example of the latter.  A situated agent can be
reactive (instinctive, driven by stimulus) or it can be deliberative
(&#8220;intellectual&#8221; in the classic AI sense). An autonomous agent can
deal exclusively with abstract information (&#8220;softbot&#8221;,
&#8220;knowbot&#8221;, or &#8220;information agent&#8221;) or it can be
<i>embodied</i> in a physical manifestation (a typical industrial robot or
an autonomous vehicle).  Combinations of <i>situated, reactive,</i> and
<i>embodied</i> define several distinct classes of autonomous agents.
</p>
<p>
The category of situated, embodied agents usually suggests autonomous
robots: mechanical devices that exist in the real world.  Sometimes robots
are studied via computational simulation.  But that practice is viewed with
suspicion by purists in the robotics field because the simulation may
diverge from reality in unpredictable ways.  There is another class of
situated, embodied agent based on a computational model. This paper will
use the term <i>virtual</i> (as in virtual reality) to denote these agents
which, rather than being simulations of a mechanical device in the real
world, are instead <b>real</b> agents in a virtual world.  (Analogous to a
<i>physically-based model</i> in computer animation.)  Hence the autonomous
characters of this paper&#8217;s title are: situated, embodied, reactive,
virtual agents.
</p>
<p>The term <i>behavior</i> has many meanings.  It can mean the complex
action of a human or other animal based on volition or instinct.  It can
mean the largely predictable actions of a simple mechanical system, or the
complex action of a chaotic system.  In virtual reality and multimedia
applications, it is sometimes used as a synonym for &#8220;animation.&#8221;
In this paper the term behavior is used to refer to the improvisational and
life-like actions of an autonomous character.
</p>
<p>
The behavior of an autonomous character can be better understood by
dividing it into several layers.  These layers are intended only for
clarity and specificity in the discussion that will follow.  Figure 1 shows
a division of motion behavior for autonomous characters into a hierarchy of
three layers: <i>action selection</i>, <i>steering</i>, and
<i>locomotion</i>.  Certainly other dissections are possible.  A similar
three layer hierarchy is described by Blumberg and Galyean [Blumberg 95],
they call the layers: <i>motivation</i>, <i>task</i>, and <i>motor</i>.
Note that while the behavioral hierarchy presented here is intended to be
widely applicable to motion behaviors, it is not well suited for other
types of autonomous actions, for example the conversational behaviors of a
&#8220;chatterbot&#8221; require a significantly different structure.
</p>

<div align="center">
<img src="Steering%20Behaviors%20For%20Autonomous%20Characters_fichiers/figure1.gif" height="175" width="442">
<br>
Figure 1: A hierarchy of motion behaviors
</div> 

<p>
Consider, for example, some cowboys tending a herd of cattle out on the
range.  A cow wanders away from the herd.  The trail boss tells a cowboy to
fetch the stray.  The cowboy says &#8220;giddy-up&#8221; to his horse and
guides it to the cow, possibly avoiding obstacles along the way.  In this
example, the trail boss represents <i>action selection:</i> noticing that
the state of the world has changed (a cow left the herd) and setting a goal
(retrieve the stray).  The <i>steering</i> level is represented by the
cowboy, who decomposes the goal into a series of simple subgoals (approach
the cow, avoid obstacles, retrieve the cow).  A subgoal corresponds to a
steering behavior for the cowboy-and-horse team.  Using various control
signals (vocal commands, spurs, reins) the cowboy steers his horse towards
the target.  In general terms, these signals express concepts like: go
faster, go slower, turn right, turn left, and so on.  The horse implements
the <i>locomotion</i> level.  Taking the cowboy&#8217;s control signals as
input, the horse moves in the indicated direction.  This motion is the
result of a complex interaction of the horse&#8217;s visual perception, its
sense of balance, and its muscles applying torques to the joints of its
skeleton.  From an engineering point of view, legged locomotion is a very
hard problem [Raibert 91], [Hodgins 95], but neither the cowboy nor the
horse give it a second thought.
</p>
<p>
This paper will focus on steering, the middle layer of the behavioral
hierarchy.  It will briefly describe a simple model of the locomotion
layer, but only in enough detail to provide a concrete foundation for the
discussion of various steering behaviors.  There will be some brief
discussion of action selection, but primarily in the context of combining
and blending basic steering behaviors.
</p>
<p>
<i>Path-finding</i> is a topic related to, but separate from, the subject
of this paper.  Path-finding algorithms such as A* and Dijkstra's operate
on networks (often representing grids) and essentially solve mazes.  Such a
solution could serve as a specification to the steering techniques
described in this paper.  An analogy might be to compare the written
driving instructions for getting from one place to another with the act of
driving the car along that route.  For an excellent over view of
path-finding see [Reese 99].
</p>
<p>
In order to understand the thrust of this work, it should be noted that the
steering behaviors discussed here relate to &#8220;fast&#8221; motion:
running versus crawling.  This is an informal notion, but is meant to
suggest that the typical velocity of a character is large relative to its
maximum turning acceleration.  As a result, the steering behaviors must
anticipate the future, and take into account eventual consequences of
current actions.
</p>

<h3>Related Work</h3>

<p>
Steering behaviors for autonomous characters draw on a long history of
related research in other fields.  Autonomous machines, servomechanisms,
and control theory have their roots in the 1940s as described in Norbert
Wiener&#8217;s 1948 book <i>Cybernetics, or Control and communication in the
Animal and the Machine</i> [Wiener 48].  The term <i>cybernetics</i> came
from a Greek word meaning <i>steersman</i>.  During the late 40s
neurophysiologist Grey Walter constructed autonomous robotic <i>turtles</i>
[Walter 50] which embodied several of the steering behaviors described here
and were among the first machines to exhibit emergent life-like behavior.
</p>
<p>
In the early 1980s Valentino Braitenberg extrapolated Walter&#8217;s
prototypes into thought experiments about a series of fanciful
&#8220;vehicles&#8221; with progressively more complex behaviors [Braitenberg
84]. David Zeltzer began applying techniques and models from artificial
intelligence to animation applications [Zeltzer 83].  And in 1987, I
created an animated behavioral model of bird flocks using techniques
closely related to those presented in this paper [Reynolds 87].
</p>
<p>
The list below of related research is divided into three general
categories: robotics, artificial intelligence, and artificial life,
although in some cases the distinction is somewhat arbitrary. Generally
these works are oriented towards animation to some extent: they are located
in the overlap between animation (or games, VR, and multimedia) and these
three other fields.
</p>
<p>
<b>Work related to robotics</b>.  Rodney Brooks popularized the
then-radical notion of building reactive controllers for robotic systems
[Brooks 85].  While originally inspired by ethological (animal behavior)
research, the work of Ron Arkin [Arkin 87, 89, 92] has centered on
application of steering behaviors to mobile robots. Arkin&#8217;s research
has paralleled much of the work presented in this paper, but his
<i>schema</i> (perception&#8250;action mappings) are expressed in terms of
potential field models as opposed to the procedural approach described
here.  In some cases this is a distinction without a difference, but in
other cases (such as obstacle avoidance) it leads to significantly
different agent behavior.  Marc Raibert and Jessica Hodgins both began in
legged robotics research and now both work in animation applications of
physically realistic legged systems.  In both cases, their work has touched
on steering and path planning aspects of these systems [Raibert 91, 91b],
[Hodgins 95].  Work by Zapata <i>et al</i>. on steering controllers for
fast mobile robots focused on strategies which had to deal with momentum
and other aspects of fast mechanical motion [Zapata 1992].  Maja Mataric
has worked extensively in collective robotics [Mataric 93] and a central
theme of this work is steering.
</p>
<p>
<b>Work related to artificial intelligence</b>. Ken Kahn created an early
system that generated animation of character motion from story descriptions
[Kahn 79]. David Zeltzer [Zeltzer 83, 90] pioneered AI-based animation,
popularizing the idea of abstract &#8220;task level&#8221; specification of
motion.  Gary Ridsdale [Ridsdale 87] created characters capable of
improvising complex motion, getting from A to B while avoiding static
obstacles and other actors.  Steve Strassmann&#8217;s Desktop Theater work
[Strassmann 1991] extended these notions to include handling of props and
emotional portrayal. Mônica Costa&#8217;s agent-based behavioral
animation work [Costa 90] allows a character to navigate around a house
while reactively avoiding obstacles.  Research on improvisational, dramatic
characters, which touches on steering behavior, is ongoing at Project Oz
(and now Zoesis) by Joseph Bates <i>et al.</i> [Bates 92] and at The
Virtual Theater Project by Barbara Hayes-Roth <i>et al.</i> [Hayes-Roth
96].
</p>
<p>
<b>Work related to artificial life </b>(and other fields).  The 1987
<i>boids</i> model of flocks, herds, schools and related group motion
[Reynolds 87], decomposed this complex group behavior to three simple
steering behaviors at the individual level.  The following year related
steering behaviors for obstacle avoidance [Reynolds 88] were presented.  At
the 1987 Artificial Life Workshop Mitchel Resnick presented work on
autonomous vehicles implemented in LEGO LOGO [Resnick 89] and Michael
Travers demonstrated his AGAR Animal Construction Kit [Travers 89].  (See
also more recent work by these authors [Resnick 93] and [Travers 94].)
Steering behaviors were a key element in The Virtual Fishtank, a multiuser
VR installation at The Computer Museum created by teams from MIT&#8217;s
Media Lab and NearLife [Resnick 98].  Armin Bruderlin procedurally
generated goal directed animation of human walking [Bruderlin 1989].
Randall Beer&#8217;s dissertation on an artificial cockroach [Beer 90] is
noteworthy for the depth and complexity of its neuroethological model.
Central to this model are neural implementation of several tropisms (such
as chemotaxis and thigmotaxis) which are direct analogs of steering
behaviors described below.  In [Wilhelms 90] Jane Wilhelms and Robert
Skinner investigate architectures for vehicle-like characters.  Thalmann
<i>et al.</i> created behavioral animation characters who navigated down
corridors and around obstacles using vision as simulated with 3D rendering
[Thalmann 90].  Michiel van de Panne created controllers for tasks like
parallel parking of an automobile using state-space search [van de Panne
90].  G. Keith Still has modeled large human crowds using a model of the
steering behavior of each individual [Still 94].  Using a modified genetic
algorithm, Karl Sims simultaneously evolved brains and bodies for
artificial creatures for various styles of locomotion and for goal seeking
[Sims 94].  In work first reported at SAB94 and updated at SAB96 [Cliff
96], Cliff and Miller coevolved pursuit and evasion behaviors for predator
and prey agents.  Xiaoyuan Tu <i>et al.</i> developed an elaborate and
strikingly realistic model of the biomechanics, locomotion, perception, and
behavior of fish in [Tu 94, 96] which included physically based locomotion,
steering behaviors, and an ethologically based system for action selection.
In [Blumberg 94] Bruce Blumberg described a detailed mechanism for complex
action selection and with Tinsley Galyean in [Blumberg 95] discussed the
design for a VR character capable of both autonomous improvisation and
response to external direction.  One application of these characters was in
the ALIVE system [Maes 95] by Patties Maes <i>et al.</i> The Improv system
by Ken Perlin and Athomas Goldberg [Perlin 96] also covers the gamut from
locomotion to action selection, but uses a unique approach based on
behavioral scripting and Perlin&#8217;s 1985 procedural synthesis of
textures [Perlin 85] applied to motion.  James Cremer and colleagues have
created autonomous drivers to serve as &#8220;extras&#8221; creating ambient
traffic in interactive automobile driving simulators [Cremer 96].  Robin
Green (of Bullfrog/EA) has developed a mature system for autonomous
characters used in Dungeon Keeper 2 which was inspired in part by an early
draft of this paper.  Dave Pottinger has provides a detailed discussion of
steering and coordination for groups of characters in games [Pottinger
1999].
</p>

<h3>Locomotion </h3>

<p>
<i>Locomotion</i> is the bottom of the three level behavioral hierarchy
described above.  The locomotion layer represents a character&#8217;s
<i>embodiment</i>.  It converts control signals from the <i>steering</i>
layer into motion of the character&#8217;s &#8220;body.&#8221; This motion is
subject to constraints imposed by the body&#8217;s physically-based model,
such as the interaction of momentum and strength (limitation of forces that
can be applied by the body).
</p>
<p>
As described above, a cowboy&#8217;s horse can be considered as an example
of the locomotion layer.  The rider&#8217;s steering decisions are conveyed
via simple control signals to the horse who converts them into motion. The
point of making the abstract distinction between steering and locomotion is
to anticipate &#8220;plugging in&#8221; a new locomotion module. Imagine
lifting the rider off of the horse and placing him on a cross-country
motorcycle.  The goal selection and steering behavior remain the same.  All
that has changed is the mechanism for mapping the control signals (go
faster, turn right, ...) into motion.  Originally it involved legged
locomotion (balance, bones, muscles) and now it involves wheeled locomotion
(engine, wheels, brakes).  The role of the rider is unchanged.
</p>
<p>
This suggests that with an appropriate convention for communicating control
signals, steering behaviors can be completely independent of the specific
locomotion scheme.  Although in practice it is necessary to compensate for
the &#8220;agility&#8221; and different &#8220;handing characteristics&#8221;
of individual locomotion systems.  This can be done by adjusting tuning
parameters for a given locomotion scheme (which is the approach taken in
the steering behaviors described below) or by using an adaptive,
self-calibrating technique (the way a human driver quickly adapts to the
characteristics of an unfamiliar automobile).  In the first case a steering
behavior might determine via its <i>a priori</i> tuning that the
character&#8217;s speed in a given situation should be 23 mph, in the second
case it might say &#8220;slow down a bit&#8221; until the same result was
obtained.
</p>
<p>
The locomotion of an autonomous character can be based on, or independent
from, its animated portrayal.  A character could be represented by a
physically-based dynamically balanced simulation of walking, providing both
realistic animation and behavioral locomotion.  Or a character may have a
very simple locomotion model (like described in the next section) to which
a static (say a spaceship) or pre-animated (like a human figure performing
a walk cycle) portrayal is attached.  A hybrid approach is to use a simple
locomotion model and an adaptive animation model, like an
inverse-kinematics driven walk cycle, to bridge the gap between abstract
locomotion and concrete terrain.  Finally, locomotion can be restricted to
the motion inherent in a fixed set of pre-animated segments (walk, run,
stop, turn left...) which are either selected discretely or blended
together.
</p>

<h3>A Simple Vehicle Model</h3>

<p>
The approach taken in this paper is to consider steering behaviors as
essentially independent from the underlying locomotion scheme.  A simple
locomotion model will be presented in order to make the discussion of
steering behaviors more concrete.  This locomotion model will be based on a
simple idealized <i>vehicle</i>.  The choice of the term
&#8220;vehicle&#8221; is inspired to some degree by [Braitenberg 84]. It is
intended to encompass a wide range of conveyances, from wheeled devices to
horses, from aircraft to submarines, and (while certainly stretching the
terminology) to include locomotion by a character&#8217;s own legs.  The
vehicle model described here is so simplistic and generic that it is an
equally good (or equally bad) approximation to all of those.
</p>
<p>
This vehicle model is based on a point mass approximation.  On the one hand
that allows a very simple and computationally cheap physically-based model
(for example, a point mass has velocity (linear momentum) but no moment of
inertia (rotational momentum)).  On the other hand, it cannot be a very
compelling physical model because point masses do not exist in the real
world.  Any physical object with mass must have a non-zero radius and hence
a moment of inertia.  This use of an oversimplified non-physical vehicle
model is merely for convenience and intended to be &#8220;without loss of
generality&#8221; &#8212; it should always be possible to substitute a more
plausible, more realistic physically based vehicle model.
</p>
<p>
A point mass is defined by a <i>position</i> property and a <i>mass</i>
property. In addition, the simple vehicle model includes a <i>velocity</i>
property. The velocity is modified by applying forces.  Because this is a
vehicle, these forces are generally self-applied, and hence limited. For
example, a typical force which adjusts a vehicle&#8217;s velocity is
<i>thrust</i>, generated by the vehicle&#8217;s own power plant, and hence
limited in magnitude by the capacity of the power plant.  For the simple
vehicle model, this notion is summarized by a single &#8220;maximum
force&#8221; parameter (<i>max_force</i>).  Most vehicles are characterized
by a top speed.  Typically this limitation is due to the interaction
between acceleration due to their finite thrust and the deceleration due to
viscous drag, friction, or (in legged systems) the momentum of
reciprocating parts. As an alternative to realistic simulation of all these
limiting forces, the simple vehicle model includes a &#8220;maximum
speed&#8221; parameter (<i>max_speed</i>).  This speed limit is enforced by
a kinematic truncation of the vehicle&#8217;s velocity vector.  Finally, the
simple vehicle model includes an <i>orientation</i>, which taken together
with the vehicle&#8217;s position form a velocity-aligned local coordinate
space to which a geometric model of the vehicle can be attached.  (The
terms <i>localize</i> and <i>globalize</i> will be used in this paper to
connote transforming vectors into and out of this local space.)
</p>

<pre>    Simple Vehicle Model:
        mass          scalar
        position      vector
        velocity      vector
        max_force     scalar
        max_speed     scalar
        orientation   <em>N</em> basis vectors
</pre>

<p>
For a 3D vehicle model, the <i>position</i> and <i>velocity</i> vector
values have three components and the <i>orientation</i> value is a set of
three vectors (or a 3x3 matrix, or a quaternion).  For a 2D vehicle, the
vectors each have two components, and the <i>orientation</i> value is two
2D basis vectors or can be represented as a single scalar heading angle.
</p>
<p>
The physics of the simple vehicle model is based on forward Euler
integration.  At each simulation step, behaviorally determined steering
forces (as limited by <i>max_force</i>) are applied to the vehicle&#8217;s
point mass.  This produces an acceleration equal to the steering force
divided by the vehicle&#8217;s mass.  That acceleration is added to the old
velocity to produce a new velocity, which is then truncated by
<i>max_speed</i>.  Finally, the velocity is added to the old position:
</p>

<pre>    steering_force = truncate (steering_direction, max_force)
    acceleration = steering_force / mass
    velocity = truncate (velocity + acceleration, max_speed)
    position = position + velocity
</pre>

<p>
The simple vehicle model maintains its velocity-aligned local space by
<i>incremental adjustment</i> from the previous time step.  The local
coordinate system is defined in terms of four vectors: a position vector
specifying the local origin, and three direction vectors serving as the
basis vectors of the space.  The basis vectors indicate the direction and
length of coordinate units in each of three mutually perpendicular
directions relative to the vehicle.  These axes will be referred to here as
<i>forward</i>, <i>up</i>, and <i>side</i>.  (These correspond, of course,
to <i>X</i>, <i>Y</i> and <i>Z</i> axes of R<sup>3</sup>.  But some people
think <i>up</i> is obviously <i>Y</i> while some think it is obviously
<i>Z</i>.  The descriptive terms will be used in place of the Cartesian
names for clarity.)
</p>
<p>
In order to remain aligned with velocity at each time step, the basis
vectors must be rotated into a new direction.  (If velocity is zero the old
orientation is retained.)  Instead of using explicit rotations, the local
space is reconstructed using a combination of substitution, approximation,
and reorthogonalization.  We start with the new velocity and an
approximation to the new <i>up</i> direction.  For example, the old
<i>up</i> direction can be used as an approximation to the new
<i>up</i>. We use the vector cross product operation to construct the new
basis vectors:
</p>

<pre>    new_forward = normalize (velocity)
    approximate_up = normalize (approximate_up)      // if needed
    new_side = cross (new_forward, approximate_up)
    new_up = cross (new_forward, new_side)
</pre>

<p>
The basic idea is that the approximate <i>up</i> is nearly perpendicular to
the new <i>forward</i> direction, because frame-to-frame changes in
orientation are typically small.  The new <i>side</i> direction will be
perpendicular to new <i>forward</i>, from the definition of cross
product. The new <i>up</i> is the cross product of the perpendicular
<i>forward</i> and <i>side</i> and so is perpendicular to each.
</p>
<p>
The concept of &#8220;velocity alignment&#8221; does not uniquely specify an
orientation.  The degree of freedom corresponding to rotation around the
<i>forward</i> axis (also known as <i>roll</i>) remains
unconstrained. Constructing the new local space relative to the previous
one (by, for example, using the old <i>up</i> direction as the initial
approximation to the new one) will ensure that the roll orientation at
least remains consistent.  Defining the &#8220;correct&#8221; roll value
requires further heuristics, based on the intended use of the vehicle
model.
</p>
<p>
For a &#8220;flying&#8221; vehicle (like aircraft, spaceship, and submarines)
it is useful to define roll in terms of <i>banking</i>.  The basic idea of
banking is to align the &#8220;floor&#8221; of the vehicle (-<i>up</i> axis)
with the apparent gravity due to centrifugal force during a turn.
Conversely we want the <i>up</i> direction to align with the centripetal
force that produced the maneuver.  In the presence of gravity, the down
direction should align with the sum of turning acceleration and
gravitational acceleration.  We also want to add in the current orientation
in order to damp out abrupt changes in roll.  So to implement banking in
the simple vehicle model, the approximate <i>up</i> direction is a weighted
sum of: steering acceleration, gravitational acceleration, and the old
<i>up</i>.
</p>
<p>
For a &#8220;surface hugging&#8221; (wheeled, sliding, or legged) vehicle, we
want to both constrain the vehicle&#8217;s position to the surface and to
align the vehicle&#8217;s <i>up</i> axis to the surface normal.  In addition
the velocity should be constrained to be purely tangential to the surface.
These requirements can be easily met if the surface manifold is represented
in such a way that an arbitrary point in space (corresponding to the old
vehicle position) can be mapped to: (1) the nearest point on the surface,
and (2) the surface normal at that point.  The velocity can be made tangent
by subtracting off the portion normal to the surface. The vehicle&#8217;s
position is set to the point on the surface, and the surface normal becomes
its <i>up</i> axis.
</p>
<p>
In this simple vehicle model, the control signal passed from the steering
behaviors to the locomotion behavior consists of exactly one vector
quantity: a desired steering force.  More realistic vehicle models would
have very different sets of control signals.  For example an automobile has
a steering wheel, accelerator and brake each of which can be represented as
scalar quantities.  It is possible to map a generalized steering force
vector into these scalar signals: the <i>side</i> component of the steering
vector can be interpreted as the steering signal, the <i>forward</i>
component of the steering vector can be mapped into the accelerator signal
if positive, or into the brake signal if negative.  These mappings can be
asymmetrical, for example a typical automobile can decelerate due to
braking much faster than it can accelerate due to engine thrust, as shown
in Figure 2.
</p>

<div align="center">
<img src="Steering%20Behaviors%20For%20Autonomous%20Characters_fichiers/figure2.gif" height="156" width="437">
<br>
Figure 2: asymmetrical steering forces
</div> 

<p>
Because of its assumption of velocity alignment, this simple vehicle model
cannot simulate effects such as skids, spins or slides.  Furthermore this
model allows the vehicle to turn when its speed is zero.  Most real
vehicles cannot do this (they are &#8220;non-holonomic&#8221;) and in any
case it allows undesirably large changes in orientation during a single
time step.  This problem can be solved by placing an additional constraint
on change of orientation, or by limiting the lateral steering component at
low speeds, or by simulating moment of inertia.
</p>

<h3>Steering Behaviors</h3>

<p>
This discussion of specific steering behaviors assumes that locomotion is
implemented by the simple vehicle model described above, and is
parameterized by a single steering force vector.  Therefore the steering
behaviors are described in terms of the geometric calculation of a vector
representing a desired steering force.  Note that generally the magnitude
of these steering vectors is irrelevant, since they will typically be
clipped to <i>max_force</i> by the vehicle model.  Note also that many of
the calls to <i>length</i> and <i>normalize</i> functions in these
formulations can be replaced by fast routines that use an approximation to
length as in [Ohashi 94].  The terms &#8220;we&#8221; or &#8220;our&#8221; will
sometimes be used to indicate the first person perspective of the character
being steered by a given behavior.  Animated diagrams illustrating these
behaviors can be found on the web at 
<a href="http://www.red.com/cwr/steer/">http://www.red.com/cwr/steer/</a>
</p>


<div align="center">
<img src="Steering%20Behaviors%20For%20Autonomous%20Characters_fichiers/figure3.gif" height="292" width="436">
<br>
Figure 3: <b>seek</b> and <b>flee</b>
</div> 


<p>
<b>Seek</b> (or pursuit of a static target) acts to steer the character
towards a specified position in global space.  This behavior adjusts the
character so that its velocity is radially aligned towards the target.
Note that this is different from an attractive force (such as gravity)
which would produce an orbital path <i>around</i> the target point. The
&#8220;desired velocity&#8221; is a vector in the direction from the
character to the target.  The length of &#8220;desired velocity&#8221; could
be <i>max_speed</i>, or it could be the character&#8217;s current speed,
depending on the particular application.  The steering vector is the
difference between this desired velocity and the character&#8217;s current
velocity, see Figure 3.
</p>

<pre>    desired_velocity = normalize (position - target) * max_speed
    steering = desired_velocity - velocity
</pre>

<p>
If a character continues to <b>seek</b>, it will eventually pass through
the target, and then turn back to approach again.  This produces motion a
bit like a moth buzzing around a light bulb.  Contrast this with the
description of <b>arrival</b> below.
</p>
<p>
<b>Flee</b> is simply the inverse of <b>seek</b> and acts to steer the
character so that its velocity is radially aligned away from the
target. The desired velocity points in the opposite direction.
</p>


<div align="center">
<img src="Steering%20Behaviors%20For%20Autonomous%20Characters_fichiers/figure4.gif" height="292" width="436">
<br>
Figure 4: <b>pursuit</b> and <b>evasion</b>
</div> 

<p>
<b>Pursuit</b> is similar to <b>seek</b> except that the quarry (target) is
another moving character.  Effective pursuit requires a prediction of the
target&#8217;s future position.  The approach taken here is to use a simple
predictor and to reevaluate it each simulation step.  For example, a linear
velocity-based predictor corresponds to the assumption that the quarry will
not turn during the prediction interval. While this assumption is often
incorrect, the resulting prediction will only be in use for about 1/30 of a
second.  The position of a character T units of time in the future
(assuming it does not maneuver) can be obtained by scaling its velocity by
T and adding that offset to its current position.  Steering for
<b>pursuit</b> is then simply the result of applying the <b>seek</b>
steering behavior to the predicted target location.  See Figure 4.
</p>
<p>
The key to this implementation of <b>pursuit</b> is the method used to
estimate the prediction interval T. Ideally, T would be the time until
interception, but that value is unknowable because the quarry can make
arbitrary and unpredictable maneuvers.  T could be assumed to be a
constant, which while naive, would produce better pursuit than simple
<b>seek</b> (which corresponds to T=0).  However for reasonable performance
T should be larger when the pursuer is far from the quarry, and small when
they are nearby.  A simple estimator of moderate quality is T=Dc where D is
the distance between pursuer and quarry, and c is a turning parameter.  A
more sophisticated estimator can be obtained by taking into account the
relative headings of pursuer and quarry, and whether the pursuer is
generally ahead of, behind, or to the side of, the quarry.  These two
metrics can be expressed in terms of simple dot products (between unit
<i>forward</i> vectors, and between the quarry&#8217;s <i>forward</i> and
the offset to the pursuer&#8217;s position).  Note that care must be taken
to reduce T (e.g to zero) when the pursuer finds itself aligned with, and
in front of, its quarry.
</p>
<p>
Another approach to both <b>seek</b> and <b>pursuit</b> is based on the
fact that when our character is on a collision course with a target, it
will appear at a constant heading in our character&#8217;s local space.
Conversely our character can steer toward interception by contriving to
keep the target at a constant heading.
</p>
<p>
<b>Evasion</b> is analogous to <b>pursuit</b>, except that <b>flee</b> is
used to steer away from the predicted future position of the target
character.  Optimal techniques for pursuit and evasion exist in the field
of control theory [Isaacs 65]. The versions given here are in tended to be
lightweight and are nonoptimal.  In natural systems, evasion is often
&#8220;intentionally&#8221; nonoptimal in order to be unpredictable, allowing
it to foil predictive pursuit strategies, see [Cliff 96].
</p>


<div align="center">
<img src="Steering%20Behaviors%20For%20Autonomous%20Characters_fichiers/figure5.gif" height="292" width="436">
<br>
Figure 5: <b>offset pursuit</b>
</div> 

<p>
<b>Offset pursuit</b> refers to steering a path which passes near, but not
directly into a moving target.  Examples would be a spacecraft doing a
&#8220;fly-by&#8221; or an aircraft doing a &#8220;strafing run&#8221;: flying
near enough to be within sensor or weapon range without colliding with the
target. The basic idea is to dynamically compute a target point which is
offset by a given radius R from the predicted future position of the
quarry, and to then use <b>seek</b> behavior to approach that offset point,
see Figure 5.  To construct the offset point: localize the predicted target
location (into our character&#8217;s local coordinate space) project the
local target onto the character&#8217;s <i>side-up</i> plane, normalize that
lateral offset, scale it by -R, add it to the local target point, and
globalize that value.
</p>

<div align="center">
<img src="Steering%20Behaviors%20For%20Autonomous%20Characters_fichiers/figure6.gif" height="292" width="436">
<br>
Figure 6: <b>arrival</b>
</div> 

<p>
<b>Arrival</b> behavior is identical to <b>seek</b> while the character is
far from its target.  But instead of moving through the target at full
speed, this behavior causes the character to slow down as it approaches the
target, eventually slowing to a stop coincident with the target, as shown
in Figure 6.  The distance at which slowing begins is a parameter of the
behavior.  This implementation is similar to <b>seek</b>: a desired
velocity is determined pointing from the character towards the target.
Outside the stopping radius this desired velocity is clipped to
<i>max_speed</i>, inside the stopping radius, desired velocity is ramped
down (e.g. linearly) to zero.<br>
</p>

<pre>    target_offset = target - position
    distance = length (target_offset)
    ramped_speed = max_speed * (distance / slowing_distance)
    clipped_speed = minimum (ramped_speed, max_speed)
    desired_velocity = (clipped_speed / distance) * target_offset
    steering = desired_velocity - velocity
</pre>

<p>
Real world examples of this behavior include a baseball player running to,
and then stopping at a base; or an automobile driving towards an
intersection and coming to a stop at a traffic light.
</p>

<div align="center">
<img src="Steering%20Behaviors%20For%20Autonomous%20Characters_fichiers/figure7.gif" height="292" width="436">
<br>
Figure 7: <b>obstacle avoidance</b>
</div> 

<p>
<b>Obstacle avoidance</b> behavior gives a character the ability to
maneuver in a cluttered environment by dodging around obstacles.  There is
an important distinction between <b>obstacle avoidance</b> and <b>flee</b>
behavior.  <b>Flee</b> will always cause a character to steer away from a
given location, whereas <b>obstacle avoidance</b> takes action only when a
nearby obstacle lies directly in front of the character. For example, if a
car was driving parallel to a wall, <b>obstacle avoidance</b> would take no
corrective steering action, but <b>flee</b> would attempt to turn away from
the wall, eventually driving perpendicular to it.
</p>
<p>
The implementation of <b>obstacle avoidance</b> behavior described here
will make a simplifying assumption that both the character and obstacle can
be reasonably approximated as spheres, although the basic concept can be
easily extend to more precise shape models.  Keep in mind that this relates
to obstacle avoidance not necessarily to <i>collision detection</i>.
Imagine an airplane trying to avoid a mountain. Neither are spherical in
shape, but it would suffice that the plane&#8217;s bounding sphere avoids
the mountain&#8217;s bounding sphere.  A decomposable hierarchy of bounding
spheres can be used for efficient representation of shapes for collision
detection [Hubbard 96], and presumably for obstacle avoidance too.  An
unrelated obstacle avoidance technique is described in [Egbert 96].
</p>
<p>
The geometrical construction of <b>obstacle avoidance</b> behavior bares
some similarity to the <b>offset pursuit</b> behavior described above.  It
is convenient to consider the geometrical situation from the
character&#8217;s local coordinate system.  The goal of the behavior is to
keep an imaginary cylinder of free space in front of the character.  The
cylinder lies along the character&#8217;s <i>forward</i> axis, has a
diameter equal to the character&#8217;s bounding sphere, and extends from
the character&#8217;s center for a distance based on the character&#8217;s
speed and agility.  An obstacle further than this distance away is not an
immediate threat.  The <b>obstacle avoidance</b> behavior considers each
obstacle in turn (perhaps using a spatial portioning scheme to cull out
distance obstacles) and determines if they intersect with the cylinder.  By
localizing the center of each spherical obstacle, the test for
non-intersection with the cylinder is very fast.  The local obstacle center
is projected onto the <i>side-up</i> plane (by setting its <i>forward</i>
coordinate to zero) if the 2D distance from that point to the local origin
is greater than the sum of the radii of the obstacle and the character,
then there is no potential collision.  Similarly obstacles which are fully
behind the character, or fully ahead of the cylinder, can be quickly
rejected.  For any remaining obstacles a line-sphere intersection
calculation is performed.  The obstacle which intersects the <i>forward</i>
axis nearest the character is selected as the &#8220;most threatening.&#8221;
Steering to avoid this obstacle is computed by negating the (lateral)
<i>side-up </i>projection of the obstacle&#8217;s center.  In Figure 7
obstacle A does not intersect the cylinder, obstacles B and C do, B is
selected for avoidance, and corrective steering is to the character&#8217;s
left.  The value returned from obstacle avoidance is either (a) the
steering value to avoid the most threatening obstacle, or (b) if no
collision is imminent, a special value (a <i>null</i> value, or the zero
vector) to indicate that no corrective steering is required at this moment.
</p>
<p>A final note regarding interaction of obstacle avoidance and goal
seeking.  Generally we only care about obstacles which are between us and
our goal.  The mountain beyond the airport is ignored by the airplane, but
the mountain between the plane and the airport is <i>very</i> important.
</p>

<div align="center">
<img src="Steering%20Behaviors%20For%20Autonomous%20Characters_fichiers/figure8.gif" height="292" width="436">
<br>
Figure 8: <b>wander</b>
</div> 

<p>
<b>Wander</b> is a type of random steering.  One easy implementation would
be to generate a random steering force each frame, but this produces rather
uninteresting motion.  It is &#8220;twitchy&#8221; and produces no sustained
turns.  A more interesting approach is to retain steering direction state
and make small random displacements to it each frame.  Thus at one frame
the character may be turning up and to the right, and on the next frame
will still be turning in almost the same direction.  The steering force
takes a &#8220;random walk&#8221; from one direction to another.  This idea
can be implemented several ways, but one that has produced good results is
to constrain the steering force to the surface of a sphere located slightly
ahead of the character.  To produce the steering force for the next frame:
a random displacement is added to the previous value, and the sum is
constrained again to the sphere&#8217;s surface.  The sphere&#8217;s radius
(the large circle in Figure 8) determines the maximum wandering
&#8220;strength&#8221; and the magnitude of the random displacement (the
small circle in Figure 8) determines the wander &#8220;rate.&#8221; Another
way to implement <b>wander</b> would be to use coherent <i>Perlin noise</i>
[Perlin 85] to generate the steering direction.
</p>
<p>
Related to wander is <b>explore</b> (where the goal is to exhaustively
cover a region of space) and <b>forage</b> (combining wandering with
resource seeking).  See [Beer 90] and [Tu 96] for more details.
</p>

<div align="center">
<img src="Steering%20Behaviors%20For%20Autonomous%20Characters_fichiers/figure9.gif" height="292" width="436">
<br>
Figure 9: <b>path following</b>
</div> 

<p>
<b>Path following</b> behavior enables a character to steer along a
predetermined path, such as a roadway, corridor or tunnel.  This is
distinct from constraining a vehicle rigidly to a path like a train rolling
along a track.  Rather <b>path following</b> behavior is intended to
produce motion such as people moving down a corridor: the individual paths
remain near, and often parallel to, the centerline of the corridor, but are
free to deviate from it.  In the implementation described here, a path will
be idealized as a <i>spine</i> and a <i>radius</i>.  The spine might be
represented as a spline curve or a &#8220;poly-line&#8221; (a series of
connected line segments).  The path is then a &#8220;tube&#8221; or
&#8220;generalized cylinder:&#8221; a circle of the specified radius, swept
along the specified spine.  The goal of the <b>path following</b> steering
behavior is to move a character along the path while staying within the
specified radius of the spine.  If the character is initially far away from
the path, it must first approach, then follow the path.
</p>
<p>
To compute steering for <b>path following</b>, a velocity-based prediction
is made of the character&#8217;s future position, as discussed above in
regard to <b>obstacle avoidance</b> behavior.  The predicted future
position is projected onto the nearest point on the path spine.  See Figure
9.  If this projection distance (from the predicted position to the nearest
on-path point) is less than the path radius, then the character is deemed
to be correctly following the path and no corrective steering is required.
Otherwise the character is veering away from the path, or is too far away
from the path.  To steer back towards the path, the <b>seek</b> behavior is
used to steer towards the on-path projection of the predicted future
position.  Like in <b>obstacle avoidance</b>, a null or zero value is
returned is returned if no corrective steering is required.  A path can be
followed without regard to direction, or in a specified direction (from A
to B or from B to A) by adjusting the target point along the path in the
desired direction.
</p>

<div align="center">
<img src="Steering%20Behaviors%20For%20Autonomous%20Characters_fichiers/figure10.gif" height="292" width="436">
<br>
Figure 10: <b>wall following</b> and <b>containment</b>
</div> 


<p>
Variations on <b>path following</b> include <b>wall following</b> and
<b>containment</b> as shown in Figure 10.  <b>Wall following</b> means to
approach a &#8220;wall&#8221; (or other surface or path) and then to maintain
a certain offset from it [Beer 90].  For a discussion of offset goals, see
<b>offset pursuit</b> above.  <b>Containment</b> refers to motion which is
restricted to remain within a certain region.  <b>Path following</b> is a
type of <b>containment</b> where the allowable region is a cylinder around
the path&#8217;s spine.  Examples of <b>containment</b> include: fish
swimming in an aquarium and hockey players skating within an ice rink.  To
implement: first predict our character&#8217;s future position, if it is
inside the allowed region no corrective steering is necessary.  Otherwise
we steer towards the allowed region.  This can be accomplished by using
<b>seek</b> with an inside point (for example, we can project the future
position to the obstacle surface, and then extend this offset to obtain a
target point) or we can determine the intersection of our path with the
boundary, find the surface normal at that point, and then use the component
of the surface normal which is perpendicular to our forward direction as
the corrective lateral steering.
</p>

<div align="center">
<img src="Steering%20Behaviors%20For%20Autonomous%20Characters_fichiers/figure11.gif" height="292" width="436">
<br>
Figure 11: <b>flow field following</b>
</div> 

<p>
<b>Flow field following</b> steering behavior provides a useful tool for
directing the motion of characters based on their position within an
environment.  It is particularly valuable in some production teams because
it allows motion specification to be made without use of programming and so
can used by the art staff directly.  In the case of game production this
person might be a &#8220;level designer&#8221; and in animation production
they might be a &#8220;scene planner&#8221; or &#8220;layout artist.&#8221;
</p>
<p>
In <b>flow field following</b> behavior the character steers to align its
motion with the local tangent of a <i>flow field</i> (also known as a
<i>force field</i> or a <i>vector field</i>). The flow field defines a
mapping from a location in space to a flow vector: imagine for example a
floor with arrows painted on it.  Such a map, typically representing the
floor plan of an environment, can be easily created by an artist with a
special purpose &#8220;paint&#8221; program which allows them to draw the
desired traffic flow with a paint brush.  The implementation of <b>flow
field following</b> is very simple.  The future position of a character is
estimated and the flow field is sampled at that location.  This flow
direction (vector F in Figure 11) is the &#8220;desired velocity&#8221; and
the steering direction (vector S) is simply the difference between the
current velocity (vector V) and the desired velocity.
</p>

<div align="center">
<img src="Steering%20Behaviors%20For%20Autonomous%20Characters_fichiers/figure12.gif" height="292" width="436">
<br>
Figure 12: <b>unaligned collision avoidance</b>
</div> 

<p>
<b>Unaligned collision avoidance</b> behavior tries to keep characters
which are moving in arbitrary directions from running into each other.
Consider your own experience of walking across a plaza or lobby full of
other walking people: avoiding collisions involves predicting potential
collisions and altering your direction and speed to prevent them.  If all
nearby characters are <i>aligned</i>, a less complicated strategy can be
used, see <b>separation</b> below.
</p>
<p>
To implement this as a steering behavior, our character considers each of
the other characters and determines (based on current velocities) when and
where the two will make their <i>nearest approach</i>. A potential for
collision exists if the nearest approach is in the future, and if the
distance between the characters at nearest approach is small enough
(indicated by circles in Figure 12). The nearest of these potential
collisions, if any, is determined. The character then steers to avoid the
site of the predicted collision. It will steer laterally to turn away from
the potential collision. It will also accelerate forward or decelerate
backwards to get to the indicate site before or after the predicted
collision.  In Figure 12 the character approaching from the right decides
to slow down and turn to the left, while the other character will speed up
and turn to the left.
</p>

<div align="center">
<img src="Steering%20Behaviors%20For%20Autonomous%20Characters_fichiers/figure13.gif" height="324" width="395">
<br>
Figure 13: neighborhood
</div> 

<p>
The next three steering behaviors: <b>separation</b>, <b>cohesion</b>, and
<b>alignment</b>, relate to groups of characters.  In each case, the
steering behavior determines how a character reacts to other characters in
its local <i>neighborhood</i>.  Characters outside of the local
neighborhood are ignored.  As shown in Figure 13, the neighborhood is
specified by a <i>distance</i> which defines when two characters are
&#8220;nearby&#8221;, and an <i>angle</i> which defines the character&#8217;s
perceptual &#8220;field of view.&#8221;
</p>

<div align="center">
<img src="Steering%20Behaviors%20For%20Autonomous%20Characters_fichiers/figure14.gif" height="292" width="436">
<br>
Figure 14: <b>separation</b>
</div> 

<p>
<b>Separation</b> steering behavior gives a character the ability to
maintain a certain separation distance from others nearby.  This can be
used to prevent characters from crowding together.  To compute steering for
<b>separation</b>, first a search is made to find other characters within
the specified neighborhood.  This might be an exhaustive search of all
characters in the simulated world, or might use some sort of spatial
partitioning or caching scheme to limit the search to local characters.
For each nearby character, a repulsive force is computed by subtracting the
positions of our character and the nearby character, normalizing, and then
applying a 1/r weighting.  (That is, the position offset vector is scaled
by 1/r<sup> 2</sup>.)  Note that 1/r is just a setting that has worked
well, not a fundamental value. These repulsive forces for each nearby
character are summed together to produce the overall steering force.  See
Figure 14.
</p>

<div align="center">
<img src="Steering%20Behaviors%20For%20Autonomous%20Characters_fichiers/figure15.gif" height="292" width="436">
<br>
Figure 15: <b>cohesion</b>
</div> 

<p><b>Cohesion</b> steering behavior gives an character the ability to
cohere with (approach and form a group with) other nearby characters.  See
Figure 15.  Steering for <b>cohesion</b> can be computed by finding all
characters in the local neighborhood (as described above for
<b>separation</b>), computing the &#8220;average position&#8221; (or
&#8220;center of gravity&#8221;) of the nearby characters.  The steering
force can applied in the direction of that &#8220;average position&#8221;
(subtracting our character position from the average position, as in the
original boids model), or it can be used as the target for <b>seek</b>
steering behavior.
</p>

<div align="center">
<img src="Steering%20Behaviors%20For%20Autonomous%20Characters_fichiers/figure16.gif" height="292" width="436">
<br>
Figure 16: <b>alignment</b>
</div> 

<p>
<b>Alignment</b> steering behavior gives an character the ability to align
itself with (that is, head in the same direction and/or speed as) other
nearby characters, as shown in Figure 16.  Steering for <b>alignment</b>
can be computed by finding all characters in the local neighborhood (as
described above for <b>separation</b>), averaging together the velocity (or
alternately, the unit <i>forward</i> vector) of the nearby characters.
This average is the &#8220;desired velocity,&#8221; and so the steering
vector is the difference between the average and our character&#8217;s
current velocity (or alternately, its unit <i>forward</i> vector).  This
steering will tend to turn our character so it is aligned with its
neighbors.
</p>
<p>
<b>Flocking</b> behavior: in addition to other applications, the
<b>separation</b>, <b>cohesion</b> and <b>alignment</b> behaviors can be
combined to produce the <i>boids</i> model of flocks, herds and schools
[Reynolds 87] (see also [Tu 94], [Tu 96] and [Hodgins 94]).  In some
applications it is sufficient to simply sum up the three steering force
vectors to produce a single combined steering for flocking (see Combining
Behaviors below).  However for better control it is helpful to first
normalize the three steering components, and then to scale them by three
weighting factors before summing them.  As a result, boid flocking behavior
is specified by nine numerical parameters: a weight (for combining), a
distance and an angle (to define the neighborhood, see Figure 13) for each
of the three component behaviors.
</p>

<div align="center">
<img src="Steering%20Behaviors%20For%20Autonomous%20Characters_fichiers/figure17.gif" height="292" width="436">
<br>
Figure 17: <b>leader following</b>
</div> 

<p>
<b>Leader following</b> behavior causes one or more character to follow
another moving character designated as the <i>leader</i>.  Generally the
followers want to stay near the leader, without crowding the leader, and
taking care to stay out of the leader&#8217;s way (in case they happen to
find them selves in front of the leader).  In addition, if there is more
than one follower, they want to avoid bumping each other.  The
implementation of <b>leader following</b> relies on <b>arrival</b> behavior
(see above) a desire to move towards a point, slowing as it draws near.
The arrival target is a point offset slightly behind the leader.  (The
offset distance might optionally increases with speed.)  If a follower
finds itself in a rectangular region in front of the leader, it will steer
laterally away from the leader&#8217;s path before resuming <b>arrival</b>
behavior.  In addition the followers use <b>separation</b> behavior to
prevent crowding each other.  See Figure 17.
</p>
<p>
Finally, here are quick sketches of some other steering behaviors that fit
into the same general category as those described in more detail
above. <b>Interpose</b> steering behavior attempts to put its character
between two other moving characters, for example a soccer player trying to
block a pass between two members of the opposing team.  The general
approach is similar to <b>pursuit</b> described above: predict the future
position of the two other characters, determine a target point by
interpolating between the future positions, and use <b>seek</b> to steer
toward the target point.  Related to <b>leader following</b> and
<b>pursuit</b>, we could <b>shadow</b> our quarry by approaching and then
using <b>alignment</b> to match their speed and heading.  The
<b>arrival</b> behavior described above can be considered a constraint on
position and speed.  This can be extended to simultaneously constrain
orientation (to produce <b>docking</b>), or a non-zero velocity, and/or to
meet these constraints at a given time.  <b>Hide</b> behavior involves
identifying a target location which is on the opposite side of an obstacle
from the opponent, and steering toward it using <b>seek</b>.
</p>
<p>

</p><h3>Combining Behaviors</h3>

<p>The individual steering behaviors described above serve as building
blocks for more complex patterns of behavior.  They are components of a
larger structure, like notes of a melody or words of a story.  In order to
make interesting and life-like behaviors we need to select among, and blend
between, these individual components.  Unless an autonomous character
exists in an very simple world, it would seldom make sense for the
character to continually execute a single steering behavior.
</p>
<p>
Combining behaviors can happen in two ways.  A character may sequentially
switch between behavioral modes as circumstances change in its world.  For
example, imagine caribou grazing in a meadow when suddenly they sense
wolves approaching.  This event triggers a discrete behavioral switch.  All
thoughts of grazing are forgotten as the caribou herd turns to flee from
the predators.  There is no tendency to mix these behaviors: a caribou will
not slow down while running from a wolf in order to grab another bite of
food.  These discrete changes of behavioral state take place at the
<i>action selection</i> level, the top of the three level behavioral
hierarchy discussed in the Introduction.  There is a extensive discussion
of action selection in [Tu 94], [Tu 96] and in [Blumberg 94].
</p>
<p>
On the other hand, some kinds of behaviors are commonly blended together,
effectively acting in parallel.  For example, as the caribou flee through
the forest, they blend <b>evasion</b> and <b>obstacle avoidance</b>
together to allow them to escape from the wolves while dodging trees. A
caribou cannot afford to ignore either component behavior, it must always
be moving in a direction that <i>both</i> takes it away from the wolf
<i>and</i> avoids collisions with trees.  This behavioral blending occurs
at the middle <i>steering</i> level of the behavioral hierarchy.
</p>
<p>
Blending of steering behaviors can be accomplished in several ways. The
most straightforward is simply to compute each of the component steering
behaviors and sum them together, possibly with a weighting factor for each
of them.  (Note that steering vectors are especially easy to blend, other
kinds of behaviors, producing other kinds of values (e.g. conversational
behaviors) could be much harder to combine.)  This simple linear
combination often works well, but has at least two shortcomings: it is not
the most computationally efficient approach, and despite adjusting the
weights, component behaviors may cancel each other out at inopportune
times.
</p>
<p>
The computation load can be decreased by observing that a character&#8217;s
momentum serves to apply a low-pass filter to changes in steering force.
So rather than compute several steering components each simulation step and
average them together, we could instead select one steering component to
compute and apply each frame, and depend on momentum (and perhaps some
explicit damping of acceleration) to blend them together.
</p>
<p>
The problem of components canceling each other out can be addressed by
assigning a priority to components.  (For example: first priority is
<b>obstacle avoidance</b>, second is <b>evasion </b>...)  The steering
controller first checks to see if <b>obstacle avoidance</b> returns a
non-zero value (indicating a potential collision), if so it uses that.
Otherwise, it moves on to the second priority behavior, and so on.
</p>
<p>
A hybrid of these techniques that the author has found useful is
&#8220;prioritized dithering&#8221;: with a certain probability the first
priority behavior is evaluated, and if it returns a non-zero (non-null)
value that will be used.  Otherwise (if the behavior returns zero, or it
was skipped over due to the random selection) the second priority behavior
is considered, and so on.
</p>
<p>
In [Reynolds 87] a blending scheme called &#8220;prioritized acceleration
allocation&#8221; was used with the boids flocking model.  The basic idea
was that by adjusting their magnitude, higher priority behaviors could
decide whether or not to leave any steering force for use by lower priority
behaviors.  In the course of several reimplementations of boids over the
years, a simple linear combination of the component behaviors has proved
sufficient.  When combining flocking with other behaviors such as obstacle
avoidance, both simple summing and prioritized dither have been used
successfully.
</p>

<h3>Conclusions</h3>

<p>
This paper defined &#8220;autonomous character&#8221; in terms of autonomous
agents and improvisational action.  It presented a decomposition of the
task of constructing motion behaviors for autonomous characters into a
three level hierarchy of: action selection, steering, and locomotion.  It
has defined a minimal implementation of the locomotion level in terms of a
&#8220;simple vehicle model.&#8221; It has then presented a collection of
simple, common steering behaviors.  (Including: <b>seek</b>, <b>flee</b>,
<b>pursuit</b>, <b>evasion</b>, <b>offset pursuit</b>, <b>arrival</b>,
<b>obstacle avoidance</b>, <b>wander</b>, <b>path following</b>, <b>wall
following</b>, <b>containment</b>, <b>flow field following,</b>
<b>unaligned collision avoidance</b>, <b>separation</b>, <b>cohesion</b>,
<b>alignment</b>, <b>flocking</b>, and <b>leader following</b>.)  Finally
it has described some techniques for blending these simple steering
behaviors together.
</p>

<h3>Acknowledgments</h3>

<p>
The techniques described in this paper have been developed over the last
twelve years, for many different projects, at several companies.  I wish to
acknowledge the helpful cooperation of all the companies and coworkers
involved.  Specifically I wish to thank the following people for managerial
support and technical collaboration.  At Sony Computer Entertainment
America: Phil Harrison, John Phua, Attila Vass, Gabor Nagy, Sky Chang, and
Tom Harper.  At DreamWorks Feature Animation: Dylan Kohler, Bart Gawboy,
Matt Arrott, Lance Williams, Saty Raghavachary, and Mike Ullner.  At
SGI&#8217;s Silicon Studio: Bob Brown, Leo Blume, Roy Hashimoto, and
especially my behavioral animation colleague Xiaoyuan Tu.  At Electronic
Arts: Luc Barthelet, Steve Crane, Kelly Pope, Steve Sims, and Frank
Giraffe.  At Symbolics Graphics Division: Tom McMahon, Andy Kopra, Larry
Malone, and Michael Wahrman.  Finally, loving thanks to my wife Lisa and
our children Eric and Dana.  Before they become fully autonomous, I hope I
steer the kids in the right direction.  Certainly they are already real
<i>characters</i>!
</p>

<h3>References</h3>

<font size="2">
</font><p>
<font size="2">Arkin, Ronald (1987) &#8220;Motor Schema Based Navigation for a Mobile
Robot: An Approach to Programming by Behavior&#8221;, Proceedings of IEEE
Conference on Robotics and Automation, pages 264-271.
</font></p>
<p>
<font size="2">Arkin, Ronald (1989) &#8220;Motor Schema-Based Mobile Robot
Navigation&#8221;, International Journal of Robotics Research, 8(4) pages
92-112.
</font></p>
<p>
<font size="2">Arkin, Ronald (1992) &#8220;Behavior-based Robot Navigation in Extended
Domains&#8221;, Journal of Adaptive Behavior, 1(2) pages 201-225.
</font></p>
<p>
<font size="2">Bates, Joseph; Loyall, Bryan; Reilly, Scott (1992) &#8220;An Architecture
for Action, Emotion, and Social Behavior&#8221;, Proceedings of the Fourth
European Workshop on Modeling Autonomous Agents in a Multi-Agent World,
S.Martino al Camino, Italy.
<a href="http://www.cs.cmu.edu/afs/cs.cmu.edu/project/oz/web/papers/CMU-CS-92-144.ps">
http://www.cs.cmu.edu/afs/cs.cmu.edu/project/oz/web/papers/CMU-CS-92-144.ps</a>
</font></p>
<p>
<font size="2">Beer, R. D. (1990). Intelligence as Adaptive Behavior: Experiments in
Computational Neuroethology. New York: Academic Press.  See also:
<a href="http://yuggoth.ces.cwru.edu/johng/robopaper/robopaper.html">
http://yuggoth.ces.cwru.edu/johng/robopaper/robopaper.html</a>
</font></p>
<p>
<font size="2">Blumberg, Bruce and Galyean, Tinsley (1995) Multi-Level Direction of
Autonomous Creature for Real-Time Virtual Environments, Proceedings of
SIGGRAPH 95, in Computer Graphics Proceedings, Annual Conference Series,
ACM SIGGRAPH, pages 47-54.
<a href="http://bruce.www.media.mit.edu/people/bruce/Siggraph95.final.ps">
http://bruce.www.media.mit.edu/people/bruce/Siggraph95.final.ps</a>
</font></p>
<p>
<font size="2">Blumberg, Bruce (1994) &#8220;Action-Selection in Hamsterdam: Lessons from
Ethology&#8221; in the Proceedings of the Third International Conference on
the Simulation of Adaptive Behavior (SAB94), D. Cliff, P. Husbands, J-A
Meyer, and S. Wilson, Editors, MIT Press, Cambridge, Massachusetts, pages
108-117
</font></p>
<p>
<font size="2">Braitenberg, Valentino (1984) Vehicles: Experiments in Synthetic
Psychology, The MIT Press, Cambridge, MA.
</font></p>
<p>
<font size="2">Brooks, Rodney A. (1985) "A Robust Layered Control System for a Mobile
Robot," IEEE Journal of Robotics and Automation 2(1), March 1986,
pp. 14--23; also MIT AI Memo 864, September 1985.  See:
<a href="http://www.ai.mit.edu/people/brooks/papers/AIM-864.pdf">
http://www.ai.mit.edu/people/brooks/papers/AIM-864.pdf</a>
</font></p>
<p>
<font size="2">Bruderlin, Armin and Calvert, Tom (1989) "Goal-Directed, Dynamic
Animation of Human Walking", ACM SIGGRAPH'89, Proceedings, vol. 23, pp
233-242.
</font></p>
<p>
<font size="2">Cliff, Dave and Miller, Geoffrey (1996) &#8220;Co-Evolution of Pursuit and
Evasion II: Simulation Methods and Results&#8221;, From Animals to Animats
4: Proceedings of the Fourth International Conference on Simulation of
Adaptive Behavior (SAB96), Maes, Mataric, Meyer, Pollack, and Wilson
editors, ISBN 0-262-63178-4, MIT Press.
<a href="http://www.cogs.susx.ac.uk/users/davec/pe.html">
http://www.cogs.susx.ac.uk/users/davec/pe.html</a>
</font></p>
<p>
<font size="2">Costa, Mônica; Feijó, Bruno; and Schwabe, Daniel (1990)
Reactive Agents in Behavioral Animation, <i>Anais do SIBGRAPI 95</i>,
Lotufo and Mascarenhas editors, São Carlos, SP, pages 159-165.
<a href="http://www.icad.puc-rio.br/%7Emonica/pubs.htm">
http://www.icad.puc-rio.br/~monica/pubs.htm</a>
</font></p>
<p>
<font size="2">Cremer, James; Kearney, J.; Willemsen, P. (1996) &#8220;A Directable Vehicle
Behavior Model for Virtual Driving Environments&#8221;, Proceedings of 1996
Conference on AI, Simulation, and Planning in High Autonomy Systems, La
Jolla, CA.  <a href="http://www.cs.uiowa.edu/%7Ecremer/papers/aisp-final.ps">
http://www.cs.uiowa.edu/~cremer/papers/aisp-final.ps</a>
</font></p>
<p>
<font size="2">Egbert, Parris and Winkler, Scott (1996) &#8220;Collision-Free Object
Movement Using Vector Fields&#8221;, IEEE Computer Graphics and
Applications, 16(4), pages 18-24.
<a href="http://www.computer.org/cga/cg1996/g4toc.htm">
http://www.computer.org/cga/cg1996/g4toc.htm</a>
</font></p>
<p>
<font size="2">Johnson, Michael (1994) WavesWorld: A Testbed for Three Dimensional
Semi-Autonomous Animated Characters, PhD Thesis, MIT Media Lab.
<a href="http://www.media.mit.edu/%7Ewave/PhDThesis/outline.html">
http://www.media.mit.edu/~wave/PhDThesis/outline.html</a>
</font></p>
<p>
<font size="2">Hayes-Roth, Barbara. and van Gent, R. (1996) &#8220;Improvisational Puppets,
Actors, and Avatars&#8221;, Proceedings of the 1996 Computer Game
Developers&#8217; Conference. Stanford Knowledge Systems Laboratory Report
KSL-96-09.  <a href="file://www-ksl.stanford.edu/pub/KSL_Reports/KSL-96-09.ps">
file://www-ksl.stanford.edu/pub/KSL_Reports/KSL-96-09.ps</a>
</font></p>
<p>
<font size="2">Hodgins, Jessica and Brogan, David (1994) &#8220;Robot Herds: Group
Behaviors for Systems with Significant Dynamics&#8221;, Proceedings of the
4th International Workshop on the Synthesis and Simulation of Living
Systems (Artificial Life IV), Brooks and Maes editors, MIT Press,
Cambridge, MA, pages 319-324.
<a href="http://www.cc.gatech.edu/gvu/animation/papers/alife.ps.gz">
http://www.cc.gatech.edu/gvu/animation/papers/alife.ps.gz</a>
</font></p>
<p>
<font size="2">Hodgins, Jessica; Wooten, W; Brogan, D; and O&#8217;Brien, J (1995)
&#8220;Animating Human Athletics&#8221;, Proceedings of SIGGRAPH 95, in
Computer Graphics Proceedings, Annual Conference Series, Robert Cook
editor, ACM SIGGRAPH, pages 71-78.
<a href="http://www.cc.gatech.edu/gvu/animation/papers/sig95.ps.gz">
http://www.cc.gatech.edu/gvu/animation/papers/sig95.ps.gz</a>
</font></p>
<p>
<font size="2">Hubbard, Philip (1996) &#8220;Approximating Polyhedra with Spheres for
Time-Critical Collision Detection&#8221;, ACM Transactions on Graphics,
15(03), pages 179-210.  <a href="http://www.acm.org/pubs/tog/hubbard96/">
http://www.acm.org/pubs/tog/hubbard96/</a>
</font></p>
<p>
<font size="2">Isaacs, Rufus (1965) Differential Games: A Mathematical Theory with
Application to Warfare and Pursuit, Control and Optimization, John Wiley
and Sons, New York.
</font></p>
<p>
<font size="2">Kahn, Kenneth (1979) &#8220;Creation of Computer Animation from Story
Descriptions&#8221;, Technical Report 540, MIT AI Lab, Cambridge, Mass.
</font></p>
<p>
<font size="2">Maes, Pattie; Darrell, T.; Blumberg, B. (1995) &#8220;The Alive System: Full
Body Interaction with Autonomous Agents&#8221;, Computer Animation &#8217;95
Conference, IEEE Press, pages 11-18.
</font></p>
<p>
<font size="2">Mataric, Maja (1993) &#8220;Designing and Understanding Adaptive Group
Behavior&#8221;, Adaptive Behavior 4(1), pages 51-80.
<a href="http://www-robotics.usc.edu/%7Emaja/">
http://www-robotics.usc.edu/~maja/</a>, 
<a href="http://www-robotics.usc.edu/%7Emaja/publications/abj95.ps.gz">
http://www-robotics.usc.edu/~maja/publications/abj95.ps.gz</a>
</font></p>
<p>
<font size="2">Ohashi, Yoshikazu (1994) &#8220;Fast Linear Approximations of Euclidean
Distance in Higher Dimensions&#8221;, in Graphics Gems IV, Paul Heckbert
editor, Academic Press.  See
<a href="ftp://princeton.edu/pub/Graphics/GraphicsGems/GemsIV/">
ftp://princeton.edu/pub/Graphics/GraphicsGems/GemsIV/</a>
</font></p>
<p>
<font size="2">Perlin, Ken (1985) &#8220;An Image Synthesizer&#8221;, in SIGGRAPH '85
Proceedings, Computer Graphics 19(3), pages 287-296.  See
<a href="http://www.mrl.nyu.edu/perlin/doc/oscar.html">
http://www.mrl.nyu.edu/perlin/doc/oscar.html</a>
</font></p>
<p>
<font size="2">Perlin, Ken (1995) &#8220;Real Time Responsive Animation With
Personality&#8221;, IEEE Transactions on Visualization and Computer
Graphics, 1(1) pages 5-15, ISSN 1077-2626.
</font></p>
<p>
<font size="2">Perlin, Ken and Goldberg, Athomas (1996) &#8220;Improv: A System for
Scripting Interactive Actors in Virtual Worlds&#8221;, Proceedings of
SIGGRAPH 96, in Computer Graphics Proceedings, Annual Conference Series,
ACM SIGGRAPH, pages 205-216.  <a href="http://www.mrl.nyu.edu/improv/">
http://www.mrl.nyu.edu/improv/</a>
<a href="http://www.mrl.nyu.edu/improv/sig-paper96/">
http://www.mrl.nyu.edu/improv/sig-paper96/</a>
</font></p>
<p>
<font size="2">Pottinger, Dave (1999) &#8220;Coordinated Unit Movement&#8221; and
&#8220;Implementing Coordinated Movement&#8221;, Game Developer Magazine,
January, 1999.  See:
<a href="http://www.gamasutra.com/features/game_design/19990122/movement_01.htm">
http://www.gamasutra.com/features/game_design/19990122/movement_01.htm</a>
<a href="http://www.gamasutra.com/features/game_design/19990129/implementing_01.htm">
http://www.gamasutra.com/features/game_design/19990129/implementing_01.htm</a>
</font></p>
<p>
<font size="2">Raibert, Marc and Hodgins, Jessica (1991) &#8220;Animation of Dynamic Legged
Locomotion&#8221;, Computer Graphics 25(4), Proceeding of SIGGRAPH 91,
Thomas Sederberg editor, ISSN 0097-8930, pages 349-358.
</font></p>
<p>
<font size="2">Raibert, M., Hodgins, J., Ringrose, R., Playter, R., Borvansky, L.,
Campbell, L., Evans, D., Crane, C., Lamb, M. (1991) &#8220;On The Run&#8221;,
SIGGRAPH `91 Electronic Theater, SIGGRAPH Video Review, Issue 72,
<a href="http://www.ai.mit.edu/projects/leglab/simulations/otr/otr.html">
http://www.ai.mit.edu/projects/leglab/simulations/otr/otr.html</a>
</font></p>
<p>
<font size="2">Reese, Bjørn and Bryan, Stout (1999) &#8220;Finding a
Pathfinder&#8221; to appear: AAAI 99 Spring Symposium on Artificial
Intelligence and Computer Games.  See also:
<a href="http://www.red.com/breese/navigation.html">
http://www.red.com/breese/navigation.html</a>
</font></p>
<p>
<font size="2">Resnick, Mitchel (1989) &#8220;LEGO, Logo, and Life&#8221;, Proceedings of
the Interdisciplinary Workshop on the Synthesis and Simulation of Living
Systems (ALife &#8217;87), SFI Studies in the Sciences of Complexity, Volume
6, Christopher Langton editor, Addison-Wesley, Redwood City, CA, USA, pages
397-406.
</font></p>
<p>
<font size="2">Resnick, Mitchel (1993) Behavior Construction Kits, CACM, 36(7),
<a href="http://el.www.media.mit.edu/groups/el/Papers/mres/BCK/BCK.html">
http://el.www.media.mit.edu:80/groups/el/Papers/mres/BCK/BCK.html</a>
</font></p>
<p>
<font size="2">Resnick, Mitchel <i>et al.</i> (1998) &#8220;The Virtual Fishtank&#8221;
<a href="http://el.www.media.mit.edu/groups/el/projects/fishtank/">
http://el.www.media.mit.edu/groups/el/projects/fishtank/</a>
</font></p>
<p>
<font size="2">Reynolds, C. W. (1987) Flocks, Herds, and Schools: A Distributed Behavioral
Model, in Computer Graphics, 21(4) (SIGGRAPH &#8217;87 Conference
Proceedings) pages 25-34.  <a href="http://www.red.com/cwr/boids.html">
http://www.red.com/cwr/boids.html</a>
</font></p>
<p>
<font size="2">Reynolds, C. W. (1988) Not Bumping Into Things, in the notes for the
SIGGRAPH 88 course Developments in Physically-Based Modeling, pages G1-G13,
published by ACM SIGGRAPH.  
<a href="http://www.red.com/cwr/nobump/nobump.html">
http://www.red.com/cwr/nobump/nobump.html</a>
</font></p>
<p>
<font size="2">Ridsdale, Gary (1987) &#8220;The Director&#8217;s Apprentice: Animating
Figures in a Constrained Environment&#8221;, Ph.D. thesis, School of
Computing Science, Simon Fraser University.
</font></p>
<p>
<font size="2">Sims, Karl (1994) &#8220;Evolving Virtual Creatures&#8221;, Proceedings of
SIGGRAPH 94, Computer Graphics Proceedings, Annual Conference Series,
Andrew Glassner editor, ACM SIGGRAPH, ISBN 0-89791-667-0, pages 15-22.
<a href="http://www.biota.org/ksims/blockies/index.html">
http://www.biota.org/ksims/blockies/index.html</a>, 
<a href="ftp://ftp.de.uu.net/pub/research/ci/Alife/karl-sims/">
ftp://ftp.de.uu.net/pub/research/ci/Alife/karl-sims/</a>
</font></p>
<p>
<font size="2">Still, G Keith (1994) &#8220;Simulating Egress using Virtual Reality - a
Perspective View of Simulation and Design&#8221;, IMAS Fire Safety on Ships.
</font></p>
<p>
<font size="2">Strassmann, Steve (1991) Desktop Theater: Automatic Generation of
Expressive Animation, PhD thesis, MIT Media Lab.
<a href="http://www.method.com/straz/straz-phd.pdf">
http://www.method.com/straz/straz-phd.pdf</a>
</font></p>
<p>
<font size="2">Thalmann, Daniel; Renault, Olivier and Magnenat-Thalmann Nadia (1990)
&#8220;A Vision-Based Approach to Behavioral Animation&#8221;, Journal of
Visualization and Computer Animation, John Wiley &amp; Sons, 1(1) pages
18-21.
</font></p>
<p>
<font size="2">Travers, Michael (1989) &#8220;Animal Construction Kits&#8221;, Proceedings
of the Interdisciplinary Workshop on the Synthesis and Simulation of Living
Systems (ALife &#8217;87), SFI Studies in the Sciences of Complexity, Volume
6, Christopher Langton editor, Addison-Wesley, Redwood City, CA, USA, pages
421-442.  <a href="http://lcs.www.media.mit.edu/people/mt/agar/agar.html">
http://lcs.www.media.mit.edu/people/mt/agar/agar.html</a>
</font></p>
<p>
<font size="2">Travers, Michael (1994) &#8220;LiveWorld: A Construction Kit for Animate
Systems&#8221;, Proceedings of ACM CHI&#8217;94 Conference on Human Factors
in Computing Systems, pages 37-38.
<a href="http://mt.www.media.mit.edu/people/mt/papers/chi94/chi94.html">
http://mt.www.media.mit.edu/people/mt/papers/chi94/chi94.html</a>
</font></p>
<p>
<font size="2">Tu, Xiaoyuan and Terzopoulos, Demetri (1994) &#8220;Artificial Fishes:
Physics, Locomotion, Perception, Behavior&#8221;, Proceedings of SIGGRAPH
94, Computer Graphics Proceedings, Annual Conference Series, Andrew
Glassner editor, ACM SIGGRAPH, ISBN 0-89791-667-0, pages 43-50.
<a href="http://www.dgp.toronto.edu/people/tu/papers/sig94.ps">
http://www.dgp.toronto.edu/people/tu/papers/sig94.ps</a>
</font></p>
<p>
<font size="2">Tu, Xiaoyuan (1996) Artificial Animals for Computer Animation:
Biomechanics, Locomotion, Perception, and Behavior, PhD dissertation,
Department of Computer Science, University of Toronto.
<a href="http://www.dgp.toronto.edu/people/tu/thesis/thesis.html">
http://www.dgp.toronto.edu/people/tu/thesis/thesis.html</a>
</font></p>
<p>
<font size="2">van de Panne, M., Fiume, E., and Vranesic, Z. G., (1990) "Reusable
Motion Synthesis Using State-Space Controllers", Proceedings of
SIGGRAPH `90, In Computer Graphics Proceedings, ACM SIGGRAPH, pages
225-234.  See <a href="http://www.dgp.toronto.edu/people/van/papers.html">
http://www.dgp.toronto.edu/people/van/papers.html</a>
</font></p>
<p>
<font size="2">Walter, W. Grey (1950) &#8220;An Imitation of Life&#8221;, Scientific
American, 182(5), pages 42-45.  (See also
<a href="http://www.uwe.ac.uk/facults/eng/ias/gwonline.html">
http://www.uwe.ac.uk/facults/eng/ias/gwonline.html</a> and
<a href="http://www.newscientist.com/ns/980725/robotman.html">
http://www.newscientist.com/ns/980725/robotman.html</a>)
</font></p>
<p>
<font size="2">Grey-Walter, W. (1953) The Living Brain. Gerald Duckworth and Co., Ltd.
</font></p>
<p>
<font size="2">Wiener, Norbert (1948) Cybernetics, or control and communication in the
animal and the machine.  Cambridge, Massachusetts: The Technology Press;
New York: John Wiley &amp; Sons, Inc.
</font></p>
<p>
<font size="2">Wilhelms, Jane and Skinner, Robert (1990) A &#8220;Notion&#8221; for
Interactive Behavioral Animation Control, IEEE Computer Graphics and
Applications, 10(3), pages 14-22.
</font></p>
<p>
<font size="2">Zapata, R., Lepinay, P., Novales, C., and Deplanques, P. (1992)
&#8220;Reactive Behaviors of Fast Mobile Robots in Unstructured
Environments: Sensor-Based Control and Neural Networks&#8221; in From
Animals to Animats 2: Proceedings of the Second International Conference on
Simulation of Adaptive Behavior (SAB92), Meyer, Roitblat and Wilson
editors, MIT Press, Cambridge, Massachusetts, pages 108-115
</font></p>
<p>
<font size="2">Zeltzer, David (1983) Knowledge-Based Animation, Proceedings
SIGGRAPH/SIGART Workshop on Motion, pages 187-192.
</font></p>
<p>
<font size="2">Zeltzer, David (1990) &#8220;Task Level Graphical Simulation: Abstraction,
Representation and Control,&#8221; in Making Them Move: Mechanics, Control
and Animation of Articulated Figures, N. Badler, B. Barsky and D. Zeltzer,
editors., Morgan Kaufmann Publishers.
</font></p>


<table bgcolor="#ffffdd" border="1" cellpadding="2" cellspacing="2">

<tbody><tr>
<th colspan="2" bgcolor="#ffddbb">
<font color="#ff0000" size="2">
Revision History:
</font>
</th>
</tr>

<tr>
<td>
<font size="2">
January 14, 1997
</font>
</td>
<td>
<font size="2">
draft submitted to SIGGRAPH 97
</font>
</td>
</tr>

<tr>
<td>
<font size="2">
February 10, 1999
</font>
</td>
<td>
<font size="2">
version for 1999 Game Developers Conference
</font>
</td>
</tr>

<tr>
<td>
<font size="2">
March 10, 1999
</font>
</td>
<td>
<font size="2">
autogenerated HTML version posted on WWW
</font>
</td>
</tr>

<tr>
<td>
<font size="2">
March 19, 1999
</font>
</td>
<td>
<font size="2">
presented at 1999 Game Developers Conference
</font>
</td>
</tr>

<tr>
<td>
<font size="2">
April 11, 1999
</font>
</td>
<td>
<font size="2">
improve HTML (move figures, add figure numbers, add links)
</font>
</td>
</tr>

<tr>
<td>
<font size="2">
April 17, 1999
</font>
</td>
<td>
<font size="2">
improve HTML (fix tags, update links, add pixel dimentions to images,
thanks <a href="http://www2.imagiware.com/RxHTML/">Doctor HTML</a>)
</font>
</td>
</tr>

<tr>
<td>
<font size="2">
May 3, 1999
</font>
</td>
<td>
<font size="2">
update link for gwonline.html
</font>
</td>
</tr>

</tbody></table>


</body></html>